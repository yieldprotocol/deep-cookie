{"url": "https://docs.code4rena.com/awarding/fairness-and-validity", "md_content": "[Code4rena](/)\n\nSearch\n\n\u2303K\n\n[Code4rena](/)\n\nSearch\n\n\u2303K\n\n[Code4rena](/)\n\nRoles\n\n[Wardens](/roles/wardens)\n\n[Sponsors](/roles/sponsors)\n\n[Judges](/roles/judges)\n\n[Certified contributors](/roles/certified-contributors)\n\nAwarding\n\n[Incentive model and awards](/awarding/incentive-model-and-awards)\n\n[Judging criteria](/awarding/judging-criteria)\n\n[Fairness and validity](/awarding/fairness-and-validity)\n\nPhilosophy\n\n[Security is about people](/philosophy/security-is-about-people)\n\n[The culture we're building](/philosophy/how-we-work)\n\n[Intentionally structured](/philosophy/intentionally-structured)\n\nOther Details\n\n[FAQ](/structure/frequently-asked-questions)\n\n[Audit timeline](/structure/our-process)\n\n[Where can I find\u2026?](/structure/where-can-i-find...)\n\n[Powered By\nGitBook](https://www.gitbook.com/?utm_source=content&utm_medium=trademark&utm_campaign=-MYGYvqTD29_fAaod9NJ)\n\n# Fairness and validity\n\nFairness, validity, and consistency\n\n##\n\nFundamental principles\n\nThese are the fundamental principles that underly how we look at the question\nof \"fairness\" in Code4rena.\n\n  1. 1.\n\nCode4rena aims to be a fair and impartial system.\n\n  2. 2.\n\nWhere the system is insufficient or vague, we depend on the judgment of fair\nand impartial individuals.\n\n  3. 3.\n\nWhen we depend too heavily on the judgment of individuals, we work to improve\nthe system long-term in iterative and sustainable ways.\n\n  4. 4.\n\nBecause we are working every day within the constraints of the systems we\nhave, we aim to be patient with the time and consideration that improvement\ntakes and gracious toward the individuals tasked by the system with making\ndifficult decisions.\n\nIt may be worth reading [this longer\npiece](https://github.com/code-423n4/org/discussions/36) on the topic of how\nour system has evolved.\n\n##\n\nExpectations of participants\n\n  * Sponsors should be able to trust that Code4rena as a system is working to help them secure their code and that their funds are a good investment toward that end.\n\n  * Wardens should be able to have clear rule expectations of contests they contribute to--as clear as possible within the constraints.\n\n  * Judges should be impartial and free to act independently to do what they see best in a given contest within the guidelines they are provided.\n\n##\n\nRole of hired staff (Code4 Corporation)\n\nThe role of staff is regulatory, supportive, and administrative:\n\n  * Code4 is a neutral party in contests dedicated to serving and collaborating with all sides of the market in driving the success of Code4rena as a platform.\n\n  * Code4 is responsible for improving documentation, process, and tools in support of the goals and expectations of each of the parties involved in Code4rena, providing information, context, and guidance to sponsors, judges, and wardens within the rules.\n\n  * Code4 has no role in determining the outcomes of findings and does not put its hand on the scale in individual contests.\n\n  * Code4 does have a role to provide sponsors, judges, and wardens with historical context on the intent of rules so that those rules can be applied appropriately when ambiguity is present.\n\n##\n\nWhat constitutes a 'valid' report'?\n\nThe validity of an audit report submission is not based on whether it is\n'true' or not. A report may contain a finding which is factually 'true' (the\nmost literal interpretation of 'valid'), but if it does not add value or if it\nis not presented in such a way that adds value to a sponsor, it may be deemed\ninvalid by a judge.\n\nThis may seem harsh and exclusive, but it is essential to consider that\nCode4rena runs audit contests, not gotcha-hunts, and Code4rena offers\nguaranteed payout for valid submissions. This means that wardens are providing\na service to sponsors and the product of those services should meet what\njudges feel is a minimum standard in order to be deemed of value.\n\nAuditing is serious, disciplined work that should provide high value\nconsultative expertise to the people paying for the work.\n\nIn that light, judges are right to have high standards. Some judges have\nalways had higher standards than others, and some judges have applied higher\nstandards in later contests than they did in earlier ones.\n\nWhile this may be seen as 'inconsistent', it is also true that standards\nwithin a specific contest will always be informed by the overall quality of a\ncontest's submissions, and that the standard in a judge's mind is always going\nto be evolving based on the aggregate quality of submissions that judge has\nbeen exposed to and the decisions other judges have made.\n\nThe correct assessment when this happens is not that a judge is being\ninconsistent, it is that they have objectively observed that the quality of\ncompetition has increased, and that observation shapes their view of the whole\nset of submissions; they are consistent in valuing submissions in the context\nof each other, which is a central way that performance in a competition is\nmeasured.\n\n##\n\nIf you disagree with a judge's decision\n\nIf you disagree with a decision, and you do not have [the +backstage\nrole](https://docs.code4rena.com/roles/certified-contributors/backstage-\nwardens), there's nothing further that can be done or changed; the judge's\ndecisions are final.\n\nHowever, if the concern regarding judging is focused on a matter of\ninconsistency or process or lack of clarity in the rules, you are encouraged\nto review the issues in https://github.com/code-423n4/org/issues and:\n\n  1. 1.\n\nSee if one of the problems described there matches the type of issue you have\nexperienced. If so, add a purely fact-based comment with additional\ninformation and another point of evidence of it being a challenge.\n\n  2. 2.\n\nSee if any of the suggestions described there would be useful to improving the\ncase you have in mind. If so, feel free to add your thoughts in support.\n\n  3. 3.\n\nIF a relevant type of issue is not already addressed there which doesn't\nrepresent the categorical concern you have, you can feel free to open an\nissue.\n\nThe purpose of issues in that repo is not to post grievances about specific\nissues but about to identify places where the process can be improved and ways\nwe can improve it.\n\n##\n\nContinued evolution of rules\n\n###\n\nRubric\n\nBecause wardens should be able to have clear rule expectations of contests\nthey contribute to, and because newer wardens do not have historical context\non the intent of various rules, it is important that we continue to document a\nrubric of what constitutes the subjective threshold of validity.\n\nAn initial rubric has been outlined\n[here](https://github.com/code-423n4/org/discussions/34) and a finalized\nversion of this rubric will soon be added to formal documentation and judging\nprocedure.\n\nNote well:\n\n  * the purpose of this proposed rubric is not to be 'more strict'. It's to continue to work toward a standard and mutually agreed expectations as to what constitutes the base level of quality for a submission.\n\n  * the scale of this rubric hasn't been used yet (someone who scored a 5 or a 10 or a 3 on some prior QA report was doing so on a band where 1 to 100 is the equivalent of 60 to 100 in the new rubric)\n\n  * by the time we ask judges to implement this, we will have a Chrome extension in place that will aid them in scoring and which will have the rubric visible to them as they grade so they are aware of the implied meaning of their grade per the rubric.\n\n[PreviousSeverity Categorization](/awarding/judging-criteria/severity-\ncategorization)[Next \\- PhilosophySecurity is about\npeople](/philosophy/security-is-about-people)\n\nLast modified 4d ago\n\nOn this page\n\nFundamental principles\n\nExpectations of participants\n\nRole of hired staff (Code4 Corporation)\n\nWhat constitutes a 'valid' report'?\n\nIf you disagree with a judge's decision\n\nContinued evolution of rules\n\nRubric\n\n"}