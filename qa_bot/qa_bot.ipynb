{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CodeArena (C4) Question Answer bot\n",
    "\n",
    "### Objective\n",
    "- This notebook has the PoC work for a Question Answer bot using C4's knowledge bases.\n",
    "- The objective of the PoC is to prototype an LLM implementation that can accurately answer questions to their expectation and at the very least perform better than their current bot from [Mava](https://www.mava.app/)\n",
    "\n",
    "### Observations from the usage of Mava\n",
    "- The platform offers Discord support management with ticketing and AI help bot features\n",
    "- For the AI help bot, the user is able to specify links to multiple knowledge sources that can be used for answering questions.\n",
    "- Based on C4's testing of the Mava bot in the private channel, the following stats were observed:-\n",
    "    - Total questions asked: 29\n",
    "    - Total questions mis-answered based on emoji reactions: 13\n",
    "    - Accuracy - ~55%\n",
    "\n",
    "### Knowledge Bases\n",
    "Based on conversations with their team, the following knowledge bases were identified to be relevant and are the same ones that Mava is using:-\n",
    "- [Main Website](https://code4rena.com/)\n",
    "- [Docs](https://docs.code4rena.com/) \n",
    "\n",
    "\n",
    "### High-level Approach\n",
    "- Crawl and scrape C4â€™s website and docs using Scrapy lib\n",
    "- Convert the html content to markdown format so that the model can better understand the context\n",
    "- Use LangChain lib to do the following:-\n",
    "    - Split the markdown header-separated sections into semantic chunks\n",
    "    - Embed and store the semantic chunks in an in-memory vector db\n",
    "    - Use the retrieval augmented functionality to answer the question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install all the third-party packages\n",
    "\n",
    "!pip install 'langchain[llms]'\n",
    "!pip install Scrapy\n",
    "!pip install html2text\n",
    "!pip install lxml\n",
    "!pip install python-dotenv\n",
    "!pip install \"unstructured[all-docs]\"\n",
    "!pip install tiktoken\n",
    "!pip install faiss-cpu \n",
    "!pip install GitPython\n",
    "!pip install notebook\n",
    "!pip install chromadb\n",
    "!pip install pandas\n",
    "!pip install rank_bm25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# General setup - you can specify OPENAI_API_KEY in .env file\n",
    "\n",
    "import logging\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import display, Markdown, Latex\n",
    "\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "OPENAI_API_KEY = os.environ.get('OPENAI_API_KEY') or getpass.getpass('Enter your OpenAI API key: ')\n",
    "\n",
    "assert OPENAI_API_KEY, \"Please set OPENAI_API_KEY in your environment variables\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to the data\n",
    "\n",
    "C4_WEBSITE_STORAGE_DIR = \"knowledge_base/c4/website\"\n",
    "C4_DOCS_STORAGE_DIR = \"knowledge_base/c4/docs\"\n",
    "C4_GH_DOCS_STORAGE_DIR = \"knowledge_base/c4/gh_docs\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crawling and Scraping using Scrapy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import scrapy\n",
    "import html2text\n",
    "import lxml.html\n",
    "import json\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "class GenericSpider(scrapy.Spider):\n",
    "    name = 'generic'\n",
    "\n",
    "    def __init__(self, domain='', storage_dir='.', *args, **kwargs):\n",
    "        super(GenericSpider, self).__init__(*args, **kwargs)\n",
    "        self.allowed_domains = [domain]\n",
    "        self.start_urls = [f'http://{domain}/']\n",
    "        self.storage_dir = storage_dir\n",
    "    \n",
    "    def parse(self, response):\n",
    "        # Remove unwanted elements using lxml\n",
    "        tree = lxml.html.fromstring(response.text)\n",
    "        \n",
    "        # Remove non-text related tags\n",
    "        for unwanted in tree.xpath('//script|//img|//video|//audio|//iframe|//object|//embed|//canvas|//svg|//link|//source|//track|//map|//area'):\n",
    "            unwanted.drop_tree()\n",
    "\n",
    "        cleaned_html = lxml.html.tostring(tree).decode('utf-8')\n",
    "\n",
    "        # Convert HTML to Markdown\n",
    "        converter = html2text.HTML2Text()\n",
    "        markdown_text = converter.handle(cleaned_html)\n",
    "\n",
    "        # Save to a markdown file in the specified directory\n",
    "        if not os.path.exists(self.storage_dir):\n",
    "            os.makedirs(self.storage_dir)\n",
    "\n",
    "        url = response.url\n",
    "        page_name = response.url.split(\"/\")[-1] if response.url.split(\"/\")[-1] else \"index\"\n",
    "\n",
    "        filename = os.path.join(self.storage_dir, f'{page_name}.json')\n",
    "\n",
    "        with open(filename, 'w') as f:\n",
    "            # Store the URL and markdown text in JSON format\n",
    "            json.dump({'url': url, 'md_content': markdown_text}, f)\n",
    "\n",
    "        # Recursively follow relative links to other pages on the same domain\n",
    "        for href in response.css('a::attr(href)').getall():\n",
    "            url = response.urljoin(href)\n",
    "            if urlparse(url).netloc in self.allowed_domains:\n",
    "                yield scrapy.Request(url, self.parse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: Data has already been scraped and saved locally as JSON files in the 'knowledge_base/c4' directory. To re-run the scraping, uncomment the code in the cell below.\n",
    "\n",
    "On re-running the crawler, if you get 'ReactorNotRestartable' error, the notebook kernel would need to be restarted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scrapy.crawler import CrawlerRunner\n",
    "# from scrapy.utils.project import get_project_settings\n",
    "# from twisted.internet import reactor\n",
    "\n",
    "# settings = get_project_settings()\n",
    "\n",
    "# runner = CrawlerRunner(settings)\n",
    "# runner.crawl(GenericSpider, domain=\"code4rena.com\", storage_dir=C4_WEBSITE_STORAGE_DIR)\n",
    "# runner.crawl(GenericSpider, domain=\"docs.code4rena.com\", storage_dir=C4_DOCS_STORAGE_DIR)\n",
    "# d = runner.join()\n",
    "# d.addBoth(lambda _: reactor.stop())\n",
    "# reactor.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get docs from Github Repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from git import Repo\n",
    "\n",
    "# repo = Repo.clone_from(\n",
    "#     \"https://github.com/code-423n4/docs\", to_path=C4_GH_DOCS_STORAGE_DIR\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieval Augmented Generation using LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load locally saved scraped data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain.document_loaders import TextLoader\n",
    "\n",
    "def load_json_files(dir):\n",
    "    loader = DirectoryLoader(dir, loader_cls=TextLoader)\n",
    "    documents = loader.load()\n",
    "    for d in documents:\n",
    "        page_content_dict = json.loads(d.page_content)\n",
    "        d.page_content = page_content_dict['md_content']\n",
    "        d.metadata['url'] = page_content_dict['url']\n",
    "    return documents\n",
    "\n",
    "c4_website_data_list = load_json_files(C4_WEBSITE_STORAGE_DIR)\n",
    "c4_docs_data_list = load_json_files(C4_DOCS_STORAGE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain.document_loaders import TextLoader\n",
    "\n",
    "loader = DirectoryLoader(C4_GH_DOCS_STORAGE_DIR, loader_cls=TextLoader)\n",
    "c4_gh_docs_data_list = loader.load()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split the markdown content into semantic chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89\n",
      "97\n",
      "72\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import (\n",
    "    RecursiveCharacterTextSplitter,\n",
    "    Language,\n",
    ")\n",
    "\n",
    "md_splitter = RecursiveCharacterTextSplitter.from_language(\n",
    "    language=Language.MARKDOWN, chunk_size=2000, chunk_overlap=200\n",
    ")\n",
    "\n",
    "\n",
    "website_chunks =  md_splitter.split_documents(c4_website_data_list)\n",
    "docs_chunks =  md_splitter.split_documents(c4_docs_data_list)\n",
    "gh_docs_chunks = md_splitter.split_documents(c4_gh_docs_data_list)\n",
    "\n",
    "print(len(website_chunks))\n",
    "print(len(docs_chunks))\n",
    "print(len(gh_docs_chunks))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Embed the semantic chunks and store in an in-memory vector db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "# NOTE: At times, OpenAI Embedding service can fail intermittently and return errorneous values such as [NaN], more info: https://github.com/langchain-ai/langchain/pull/7070\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "vectorstore = Chroma(\"vectorstore_1\", embeddings, collection_metadata={\"hnsw:space\": \"cosine\"})\n",
    "\n",
    "vectorstore.add_documents(website_chunks)\n",
    "#vectorstore.add_documents(docs_chunks)\n",
    "vectorstore.add_documents(gh_docs_chunks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieval Augmented Generation\n",
    "Workflow \n",
    "1. Use faster LLM (GPT-3.5) to generate 3 rephrased variants of the original user question to improve question quality which in-turn should improve retrieval\n",
    "2. Use the rephrased question to generate the final answer using RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Generate rephrased questions\n",
    "Use faster LLM (GPT-3.5) to generate 3 rephrased variants of the original user question to improve question quality which in-turn should improve retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What is the meaning of scout awards?',\n",
       " 'Can you explain what scout awards are?',\n",
       " 'Could you provide a description of scout awards?']"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = \"\"\"You are a teacher who is helping a student ask the right questions about a service so that they can look in the most relevant places to find the answer. \n",
    "# INSTRUCTIONS\n",
    "- You are given student's question below\n",
    "- Using the original question, generate 3 alternative questions that are rephrased to be not vague or ambiguous so as to clearly convey the same meaning and context as the original question\n",
    "- Return the final result as a JSON object containing a list of rephrased questions as \"new_questions\" field\n",
    "\n",
    "# QUESTION\n",
    "{question}\n",
    "\n",
    "# RESULT\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def generate_rephrased_questions(question):\n",
    "    chat = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "    llm_chain = LLMChain(llm=chat, prompt=PromptTemplate.from_template(prompt_template))\n",
    "\n",
    "    result = llm_chain(inputs={\"question\": question}, return_only_outputs=True)\n",
    "    result_dict = json.loads(result['text'])\n",
    "    new_questions = result_dict['new_questions']\n",
    "    return new_questions\n",
    "\n",
    "generate_rephrased_questions(\"What are scout awards?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Generate final answer using RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_result(question, result):\n",
    "    display(Markdown(f\"### Question\"))\n",
    "    display(Markdown(\"ORIGINAL: \" + question))\n",
    "    display(Markdown(\"REPHRASED: \" + f\"{result['rephrased_question'] if result['rephrased_question'] else 'None'}\"))\n",
    "\n",
    "    display(Markdown(f\"### Answer\"))\n",
    "    display(Markdown(result[\"result\"]))\n",
    "\n",
    "    display(Markdown(f\"### Sources\"))\n",
    "    sources = [r.metadata['url'] if 'url' in r.metadata else r.metadata['source'] for r in result[\"source_documents\"] ]\n",
    "    print(\", \".join(sources))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "qa = RetrievalQA.from_chain_type(llm=ChatOpenAI(model_name=\"gpt-4\", temperature=0), chain_type=\"stuff\", retriever=vectorstore.as_retriever(), return_source_documents=True)\n",
    "\n",
    "\n",
    "def call_llm(question, use_rephrased_questions=True):\n",
    "    if not use_rephrased_questions:\n",
    "        result = qa({\"query\": question})\n",
    "        result['rephrased_question'] = None\n",
    "        return result\n",
    "\n",
    "\n",
    "    # Get rephrased questions\n",
    "    rephrased_questions = generate_rephrased_questions(question)\n",
    "\n",
    "    # Attempt each question until a valid result is found\n",
    "    for q in rephrased_questions:\n",
    "        result = qa({\"query\": q})\n",
    "        answer = result['result']\n",
    "        result['rephrased_question'] = None\n",
    "        \n",
    "        # If the model is unable to find an answer, it returns 'sorry' in the response, we try again with a different question\n",
    "        if 'sorry' in answer.lower():\n",
    "            continue\n",
    "        else:\n",
    "            result['rephrased_question'] = q\n",
    "            break\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AutoEvaluator\n",
    "Using LangChain's [AutoEvaluator technique](https://autoevaluator.langchain.com/) to evaluate the bot's performance on the dataset of C4 questions correctly answered by Mava as per team feedback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "# load yaml file\n",
    "with open('knowledge_base/c4/c4_mava_correct_ans_set.yaml') as file:\n",
    "    # The FullLoader parameter handles the conversion from YAML\n",
    "    # scalar values to Python the dictionary format\n",
    "    yaml_data = yaml.load(file, Loader=yaml.FullLoader)\n",
    "\n",
    "mava_questions = [d['question'] for d in yaml_data]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\" \n",
    "    You are a grader trying to determine if a set of retrieved documents will help a student answer a question. \\n\n",
    "\n",
    "    Here is the question: \\n\n",
    "    {query}\n",
    "\n",
    "    Here are the documents retrieved to answer question: \\n\n",
    "    {result}\n",
    "    \n",
    "    Here is the correct answer to the question: \\n \n",
    "    {answer}\n",
    "   \n",
    "    Criteria: \n",
    "      relevance: Do all of the documents contain information that will help the student arrive that the correct answer to the question?\"\n",
    "\n",
    "    Your response should be as follows:\n",
    "\n",
    "    GRADE: (Correct or Incorrect, depending if all of the documents retrieved meet the criterion)\n",
    "    (line break)\n",
    "    JUSTIFICATION: (Write out in a step by step manner your reasoning about the criterion to be sure that your conclusion is correct. Use three sentences maximum. Keep the answer as concise as possible.)\n",
    "    \"\"\"\n",
    "\n",
    "GRADE_DOCS_PROMPT = PromptTemplate(input_variables=['result', 'answer', 'query'], template=template)\n",
    "\n",
    "template = \"\"\"You are a teacher grading a quiz. \n",
    "You are given a question, the student's answer, and the true answer, and are asked to score the student answer as either Correct or Incorrect.\n",
    "\n",
    "Example Format:\n",
    "QUESTION: question here\n",
    "STUDENT ANSWER: student's answer here\n",
    "TRUE ANSWER: true answer here\n",
    "GRADE: Correct or Incorrect here\n",
    "\n",
    "Grade the student answers based ONLY on their factual accuracy. Ignore differences in punctuation and phrasing between the student answer and true answer. It is OK if the student answer contains more information than the true answer, as long as it does not contain any conflicting statements. If the student answers that there is no specific information provided in the context, then the answer is Incorrect. Begin! \n",
    "\n",
    "QUESTION: {query}\n",
    "STUDENT ANSWER: {result}\n",
    "TRUE ANSWER: {answer}\n",
    "GRADE:\n",
    "\n",
    "Your response should be as follows:\n",
    "\n",
    "GRADE: (Correct or Incorrect)\n",
    "(line break)\n",
    "JUSTIFICATION: (Without mentioning the student/teacher framing of this prompt, explain why the STUDENT ANSWER is Correct or Incorrect. Use one or two sentences maximum. Keep the answer as concise as possible.)\n",
    "\"\"\"\n",
    "\n",
    "GRADE_ANSWER_PROMPT = PromptTemplate(input_variables=[\"query\", \"result\", \"answer\"], template=template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.evaluation.qa import QAEvalChain\n",
    "\n",
    "def grade_model_answer(predicted_dataset, predictions):\n",
    "\n",
    "    # Create an evaluation chain\n",
    "    eval_chain = QAEvalChain.from_llm(\n",
    "        llm=ChatOpenAI(model_name=\"gpt-4\", temperature=0),\n",
    "        prompt=GRADE_ANSWER_PROMPT\n",
    "    )\n",
    "\n",
    "    # Evaluate the predictions and ground truth using the evaluation chain\n",
    "    graded_outputs = eval_chain.evaluate(\n",
    "        predicted_dataset,\n",
    "        predictions,\n",
    "        question_key=\"question\",\n",
    "        prediction_key=\"result\"\n",
    "    )\n",
    "\n",
    "    return graded_outputs\n",
    "\n",
    "\n",
    "def grade_model_retrieval(gt_dataset, predictions):\n",
    "    # Create an evaluation chain\n",
    "    eval_chain = QAEvalChain.from_llm(\n",
    "        llm=ChatOpenAI(model_name=\"gpt-4\", temperature=0),\n",
    "        prompt=GRADE_DOCS_PROMPT\n",
    "    )\n",
    "\n",
    "    # Evaluate the predictions and ground truth using the evaluation chain\n",
    "    graded_outputs = eval_chain.evaluate(\n",
    "        gt_dataset,\n",
    "        predictions,\n",
    "        question_key=\"question\",\n",
    "        prediction_key=\"result\"\n",
    "    )\n",
    "    return graded_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "bot_answers = []\n",
    "source_docs = []\n",
    "for d in yaml_data:\n",
    "    result = call_llm(d['question'])\n",
    "    bot_answers.append(result['result'])\n",
    "    source_docs.append(result['source_documents'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = [{'result': a} for a in bot_answers]\n",
    "\n",
    "answer_grades = grade_model_answer(yaml_data, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_docs = []\n",
    "for i, d in enumerate(yaml_data):\n",
    "    retrieved_doc_text = \"\"\n",
    "    for j, doc in enumerate(source_docs[i]):\n",
    "        retrieved_doc_text += \"Doc %s: \" % str(j + 1) + doc.page_content + \" \"\n",
    "    retrieved = {\"question\": d[\"question\"], \"answer\": d[\"answer\"], \"result\": retrieved_doc_text}\n",
    "    retrieved_docs.append(retrieved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieval_grades = grade_model_retrieval(yaml_data, retrieved_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>Mava correct answer (True value)</th>\n",
       "      <th>Bot answers</th>\n",
       "      <th>Retrieval relevancy score</th>\n",
       "      <th>Answer similarity score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hi, how can I get backstage access?</td>\n",
       "      <td>To get backstage access, you need to become a ...</td>\n",
       "      <td>To obtain +Backstage access, you need to meet ...</td>\n",
       "      <td>Correct</td>\n",
       "      <td>Incorrect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>how long does it take until findings are relea...</td>\n",
       "      <td>Based on the context provided, the findings fr...</td>\n",
       "      <td>The audit report is published and audit issues...</td>\n",
       "      <td>Correct</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>When can I talk about findings?</td>\n",
       "      <td>You can talk about your findings after the con...</td>\n",
       "      <td>You can discuss the findings after the audit r...</td>\n",
       "      <td>Incorrect</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How do I change my wallet address?</td>\n",
       "      <td>To change your wallet address, follow these st...</td>\n",
       "      <td>To update your wallet address, you need to:\\n\\...</td>\n",
       "      <td>Correct</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What are scouts?</td>\n",
       "      <td>In the context of Code4rena, Scouts are indivi...</td>\n",
       "      <td>Scouts in the context of Code4rena are individ...</td>\n",
       "      <td>Correct</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>How long does the contest process usually take?</td>\n",
       "      <td>Based on the provided context, the contest pro...</td>\n",
       "      <td>Most audits typically run for 3-7 days.</td>\n",
       "      <td>Correct</td>\n",
       "      <td>Incorrect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>how does certification work?</td>\n",
       "      <td>The certification process at Code4rena works i...</td>\n",
       "      <td>The certification process is as follows:\\n\\n1....</td>\n",
       "      <td>Correct</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Can I use bots to analyze code?</td>\n",
       "      <td>Yes, you can use bots to analyze code. In fact...</td>\n",
       "      <td>Yes, it is possible to utilize bots for code a...</td>\n",
       "      <td>Correct</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>What is a lookout?</td>\n",
       "      <td>In the context provided, a lookout is a role i...</td>\n",
       "      <td>A Lookout in the context of Code4rena's compet...</td>\n",
       "      <td>Incorrect</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0                Hi, how can I get backstage access?   \n",
       "1  how long does it take until findings are relea...   \n",
       "2                    When can I talk about findings?   \n",
       "3                 How do I change my wallet address?   \n",
       "4                                   What are scouts?   \n",
       "5    How long does the contest process usually take?   \n",
       "6                       how does certification work?   \n",
       "7                    Can I use bots to analyze code?   \n",
       "8                                 What is a lookout?   \n",
       "\n",
       "                    Mava correct answer (True value)  \\\n",
       "0  To get backstage access, you need to become a ...   \n",
       "1  Based on the context provided, the findings fr...   \n",
       "2  You can talk about your findings after the con...   \n",
       "3  To change your wallet address, follow these st...   \n",
       "4  In the context of Code4rena, Scouts are indivi...   \n",
       "5  Based on the provided context, the contest pro...   \n",
       "6  The certification process at Code4rena works i...   \n",
       "7  Yes, you can use bots to analyze code. In fact...   \n",
       "8  In the context provided, a lookout is a role i...   \n",
       "\n",
       "                                         Bot answers  \\\n",
       "0  To obtain +Backstage access, you need to meet ...   \n",
       "1  The audit report is published and audit issues...   \n",
       "2  You can discuss the findings after the audit r...   \n",
       "3  To update your wallet address, you need to:\\n\\...   \n",
       "4  Scouts in the context of Code4rena are individ...   \n",
       "5            Most audits typically run for 3-7 days.   \n",
       "6  The certification process is as follows:\\n\\n1....   \n",
       "7  Yes, it is possible to utilize bots for code a...   \n",
       "8  A Lookout in the context of Code4rena's compet...   \n",
       "\n",
       "  Retrieval relevancy score Answer similarity score  \n",
       "0                   Correct               Incorrect  \n",
       "1                   Correct                 Correct  \n",
       "2                 Incorrect                 Correct  \n",
       "3                   Correct                 Correct  \n",
       "4                   Correct                 Correct  \n",
       "5                   Correct               Incorrect  \n",
       "6                   Correct                 Correct  \n",
       "7                   Correct                 Correct  \n",
       "8                 Incorrect                 Correct  "
      ]
     },
     "execution_count": 417,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"question\": [d['question'] for d in yaml_data],\n",
    "    \"Mava correct answer (True value)\": [d['answer'] for d in yaml_data],\n",
    "    \"Bot answers\": [p['result'] for p in predictions],\n",
    "    \"Retrieval relevancy score\": ['Incorrect' if 'Incorrect' in g['results'] else 'Correct' for g in retrieval_grades],\n",
    "    \"Answer similarity score\": ['Incorrect' if 'Incorrect' in g['results'] else 'Correct' for g in answer_grades]\n",
    "})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HyDE technique\n",
    "This technique can help improve information retrieval\n",
    "\n",
    "https://python.langchain.com/docs/use_cases/question_answering/how_to/hyde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore_hyde = Chroma(\"store_hyde_1\", embeddings, collection_metadata={\"hnsw:space\": \"cosine\"})\n",
    "vectorstore_hyde.add_documents(website_chunks)\n",
    "vectorstore_hyde.add_documents(gh_docs_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores.base import VectorStoreRetriever\n",
    "from langchain.callbacks.manager import (\n",
    "    AsyncCallbackManagerForRetrieverRun,\n",
    "    CallbackManagerForRetrieverRun,\n",
    ")\n",
    "from langchain.docstore.document import Document\n",
    "from typing import List\n",
    "\n",
    "class HydeRetriever(VectorStoreRetriever):\n",
    "\n",
    "    def _get_relevant_documents(\n",
    "        self, query: str, *, run_manager: CallbackManagerForRetrieverRun\n",
    "    ) -> List[Document]:\n",
    "        llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "        web_search_template = \"\"\"Please write a passage to answer the question \n",
    "        Question: {QUESTION}\n",
    "        Passage:\"\"\"\n",
    "\n",
    "        web_search = PromptTemplate(template=web_search_template, input_variables=[\"QUESTION\"])\n",
    "\n",
    "        llm_chain = LLMChain(llm=llm, prompt=web_search)\n",
    "\n",
    "        result = llm_chain(inputs={\"QUESTION\": query}, return_only_outputs=True)\n",
    "        hyquery = result['text']\n",
    "\n",
    "        return super()._get_relevant_documents(hyquery, run_manager=run_manager)\n",
    "\n",
    "\n",
    "hyde_retriever = HydeRetriever(vectorstore=vectorstore_hyde)\n",
    "\n",
    "hyde_retriever.get_relevant_documents(\"How can I access findings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "qa = RetrievalQA.from_chain_type(llm=ChatOpenAI(model_name=\"gpt-4\", temperature=0), chain_type=\"stuff\", retriever=hyde_retriever, return_source_documents=True)\n",
    "\n",
    "\n",
    "def call_hyde_llm(question):\n",
    "    result = qa({\"query\": question})\n",
    "    result['rephrased_question'] = None\n",
    "    return result\n",
    "\n",
    "def ask_hyde(question):\n",
    "    result = call_hyde_llm(question)\n",
    "    display_result(question, result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vector Store with Sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:chromadb.telemetry.posthog:Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.\n",
      "WARNING:langchain.embeddings.openai:Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised APIError: OpenAI API returned an empty embedding.\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "# NOTE: At times, OpenAI Embedding service can fail intermittently and return errorneous values such as [NaN], more info: https://github.com/langchain-ai/langchain/pull/7070\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "vectorstore_with_sources = Chroma(\"vectorstore_with_sources6\", embeddings, collection_metadata={\"hnsw:space\": \"cosine\"})\n",
    "\n",
    "for i, d in enumerate(website_chunks):\n",
    "    d.metadata['source'] = f\"w{i}-pl\"\n",
    "    vectorstore_with_sources.add_documents([d])\n",
    "\n",
    "for i, d in enumerate(gh_docs_chunks):\n",
    "    local_path = d.metadata['source']\n",
    "    d.metadata['source'] = f\"g{i}-pl\"\n",
    "    d.metadata['url'] = f\"{local_path.replace(C4_GH_DOCS_STORAGE_DIR, 'https://github.com/code-423n4/docs/blob/main/')}\"\n",
    "    vectorstore_with_sources.add_documents([d])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MultiQuery approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "multiquery_retriever = MultiQueryRetriever.from_llm(\n",
    "    retriever=vectorstore_with_sources.as_retriever(), llm=llm\n",
    ")\n",
    "import logging\n",
    "\n",
    "logging.basicConfig()\n",
    "logging.getLogger(\"langchain.retrievers.multi_query\").setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import BM25Retriever, EnsembleRetriever\n",
    "\n",
    "lowercased_website_chunks = []\n",
    "for d in website_chunks:\n",
    "    dd = d.copy()\n",
    "    dd.page_content = d.page_content.lower()\n",
    "    lowercased_website_chunks.append(dd)\n",
    "\n",
    "\n",
    "lowercased_gh_docs_chunks = []\n",
    "for d in gh_docs_chunks:\n",
    "    dd = d.copy()\n",
    "    dd.page_content = d.page_content.lower()\n",
    "    lowercased_gh_docs_chunks.append(dd)\n",
    "\n",
    "bm25_retriever = BM25Retriever.from_documents(lowercased_website_chunks + lowercased_gh_docs_chunks)\n",
    "bm25_retriever.k = 2\n",
    "\n",
    "ensemble_retriever = EnsembleRetriever(retrievers=[bm25_retriever, multiquery_retriever], weights=[0.5, 0.5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQAWithSourcesChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "\n",
    "model = ChatOpenAI(model_name=\"gpt-4\", temperature=0)\n",
    "\n",
    "qa_with_sources = RetrievalQAWithSourcesChain.from_chain_type(model, chain_type=\"stuff\", retriever=ensemble_retriever, return_source_documents=True)\n",
    "\n",
    "\n",
    "def run_qa_with_sources(question):\n",
    "    \n",
    "    # Santize the question by removing any trailing question marks\n",
    "    sanitized_question = question.rstrip(\"?\")\n",
    "\n",
    "    result = qa_with_sources({\"question\": sanitized_question}, return_only_outputs=True)\n",
    "\n",
    "    answer = result['answer']\n",
    "    source_ids = result['sources']\n",
    "    source_docs = result['source_documents']\n",
    "\n",
    "    source_urls = set()\n",
    "    for d in source_docs:\n",
    "        metadata = d.metadata\n",
    "        source_id = metadata['source']\n",
    "        url = metadata['url']\n",
    "        if source_id in source_ids:\n",
    "            source_urls.add(url)\n",
    "    return dict(answer=answer, source_urls=source_urls, source_docs=source_docs)\n",
    "\n",
    "def ask(question):\n",
    "    result = run_qa_with_sources(question)\n",
    "\n",
    "    display(Markdown(f\"### Question\"))\n",
    "    display(Markdown(\"ORIGINAL: \" + question))\n",
    "\n",
    "    display(Markdown(f\"### Answer\"))\n",
    "    display(Markdown(result[\"answer\"]))\n",
    "\n",
    "    display(Markdown(f\"### Sources\"))\n",
    "    print(\", \".join(result['source_urls']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auto_eval():\n",
    "    bot_answers = []\n",
    "    source_docs = []\n",
    "    for d in yaml_data:\n",
    "        result = run_qa_with_sources(d['question'])\n",
    "        bot_answers.append(result['answer'])\n",
    "        source_docs.append(result['source_docs'])\n",
    "    \n",
    "    predictions = [{'result': a} for a in bot_answers]\n",
    "\n",
    "    answer_grades = grade_model_answer(yaml_data, predictions)\n",
    "\n",
    "    retrieved_docs = []\n",
    "    for i, d in enumerate(yaml_data):\n",
    "        retrieved_doc_text = \"\"\n",
    "        for j, doc in enumerate(source_docs[i]):\n",
    "            retrieved_doc_text += \"Doc %s: \" % str(j + 1) + doc.page_content + \" \"\n",
    "        retrieved = {\"question\": d[\"question\"], \"answer\": d[\"answer\"], \"result\": retrieved_doc_text}\n",
    "        retrieved_docs.append(retrieved)\n",
    "\n",
    "    retrieval_grades = grade_model_retrieval(yaml_data, retrieved_docs)\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        \"question\": [d['question'] for d in yaml_data],\n",
    "        \"Mava correct answer (True value)\": [d['answer'] for d in yaml_data],\n",
    "        \"Bot answers\": [p['result'] for p in predictions],\n",
    "        \"Retrieval relevancy score\": ['Incorrect' if 'Incorrect' in g['results'] else 'Correct' for g in retrieval_grades],\n",
    "        \"Answer similarity score\": ['Incorrect' if 'Incorrect' in g['results'] else 'Correct' for g in answer_grades]\n",
    "    })\n",
    "    print(f\"Bot Accuracy: {df['Answer similarity score'].value_counts()['Correct'] / len(df['Answer similarity score'])}\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot Accuracy: 0.8888888888888888\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>Mava correct answer (True value)</th>\n",
       "      <th>Bot answers</th>\n",
       "      <th>Retrieval relevancy score</th>\n",
       "      <th>Answer similarity score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hi, how can I get backstage access?</td>\n",
       "      <td>To get backstage access, you need to become a ...</td>\n",
       "      <td>To get backstage access, you need to become a ...</td>\n",
       "      <td>Correct</td>\n",
       "      <td>Incorrect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>how long does it take until findings are relea...</td>\n",
       "      <td>Based on the context provided, the findings fr...</td>\n",
       "      <td>The findings are released between 42 to 60 day...</td>\n",
       "      <td>Correct</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>When can I talk about findings?</td>\n",
       "      <td>You can talk about your findings after the con...</td>\n",
       "      <td>You can talk about findings after the findings...</td>\n",
       "      <td>Incorrect</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How do I change my wallet address?</td>\n",
       "      <td>To change your wallet address, follow these st...</td>\n",
       "      <td>You can change your wallet address by logging ...</td>\n",
       "      <td>Correct</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What are scouts?</td>\n",
       "      <td>In the context of Code4rena, Scouts are indivi...</td>\n",
       "      <td>Scouts in the context of Code4rena are individ...</td>\n",
       "      <td>Incorrect</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>How long does the contest process usually take?</td>\n",
       "      <td>Based on the provided context, the contest pro...</td>\n",
       "      <td>The contest process usually takes between 42 t...</td>\n",
       "      <td>Correct</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>how does certification work?</td>\n",
       "      <td>The certification process at Code4rena works i...</td>\n",
       "      <td>Certification works by submitting an applicati...</td>\n",
       "      <td>Correct</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Can I use bots to analyze code?</td>\n",
       "      <td>Yes, you can use bots to analyze code. In fact...</td>\n",
       "      <td>Yes, you can use bots to analyze code. Code4re...</td>\n",
       "      <td>Correct</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>What is a lookout?</td>\n",
       "      <td>In the context provided, a lookout is a role i...</td>\n",
       "      <td>In the context of Code4rena's competitions, a ...</td>\n",
       "      <td>Correct</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0                Hi, how can I get backstage access?   \n",
       "1  how long does it take until findings are relea...   \n",
       "2                    When can I talk about findings?   \n",
       "3                 How do I change my wallet address?   \n",
       "4                                   What are scouts?   \n",
       "5    How long does the contest process usually take?   \n",
       "6                       how does certification work?   \n",
       "7                    Can I use bots to analyze code?   \n",
       "8                                 What is a lookout?   \n",
       "\n",
       "                    Mava correct answer (True value)  \\\n",
       "0  To get backstage access, you need to become a ...   \n",
       "1  Based on the context provided, the findings fr...   \n",
       "2  You can talk about your findings after the con...   \n",
       "3  To change your wallet address, follow these st...   \n",
       "4  In the context of Code4rena, Scouts are indivi...   \n",
       "5  Based on the provided context, the contest pro...   \n",
       "6  The certification process at Code4rena works i...   \n",
       "7  Yes, you can use bots to analyze code. In fact...   \n",
       "8  In the context provided, a lookout is a role i...   \n",
       "\n",
       "                                         Bot answers  \\\n",
       "0  To get backstage access, you need to become a ...   \n",
       "1  The findings are released between 42 to 60 day...   \n",
       "2  You can talk about findings after the findings...   \n",
       "3  You can change your wallet address by logging ...   \n",
       "4  Scouts in the context of Code4rena are individ...   \n",
       "5  The contest process usually takes between 42 t...   \n",
       "6  Certification works by submitting an applicati...   \n",
       "7  Yes, you can use bots to analyze code. Code4re...   \n",
       "8  In the context of Code4rena's competitions, a ...   \n",
       "\n",
       "  Retrieval relevancy score Answer similarity score  \n",
       "0                   Correct               Incorrect  \n",
       "1                   Correct                 Correct  \n",
       "2                 Incorrect                 Correct  \n",
       "3                   Correct                 Correct  \n",
       "4                 Incorrect                 Correct  \n",
       "5                   Correct                 Correct  \n",
       "6                   Correct                 Correct  \n",
       "7                   Correct                 Correct  \n",
       "8                   Correct                 Correct  "
      ]
     },
     "execution_count": 548,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto_eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Questions that were answered incorrectly by the Mava bot as per emoji reaction in the test channel\n",
    "MAVA_MISANSWERED_QUES = [\n",
    "    \"Am I allowed to use AI in an audit?\",\n",
    "    \"Can I change my Code4rena username?\",\n",
    "    \"How do I book a solo audit?\",\n",
    "    \"Do I need to be certified to participate in an audit?\",\n",
    "    \"How do bot races work?\",\n",
    "    \"Can I change my Code4rena profile name?\",\n",
    "    \"What are scout awards?\",\n",
    "    \"What are analysis reports?\",\n",
    "    \"what is an analysis finding?\",\n",
    "    \"My name wasn't in the award announcements. When can I check on my results?\",\n",
    "    \"How long does the certification process take?\",\n",
    "    \"How can I access findings.csv?\",\n",
    "    \"Can I use chatgpt?\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_ques = [d['question'] for d in yaml_data]\n",
    "eval_set = labeled_ques + MAVA_MISANSWERED_QUES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_results = []\n",
    "for q in eval_set:\n",
    "    result = run_qa_with_sources(q)\n",
    "    eval_results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>Bot answers</th>\n",
       "      <th>Sources</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hi, how can I get backstage access?</td>\n",
       "      <td>To get backstage access, you need to meet the ...</td>\n",
       "      <td>https://github.com/code-423n4/docs/blob/main//...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>how long does it take until findings are relea...</td>\n",
       "      <td>The findings are released between 42 to 60 day...</td>\n",
       "      <td>https://github.com/code-423n4/docs/blob/main//...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>When can I talk about findings?</td>\n",
       "      <td>You can talk about findings after they are mad...</td>\n",
       "      <td>https://github.com/code-423n4/docs/blob/main//...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How do I change my wallet address?</td>\n",
       "      <td>You can change your wallet address by logging ...</td>\n",
       "      <td>https://github.com/code-423n4/docs/blob/main//...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What are scouts?</td>\n",
       "      <td>Scouts in the context of Code4rena focus on sc...</td>\n",
       "      <td>https://code4rena.com/how-it-works, https://gi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>How long does the contest process usually take?</td>\n",
       "      <td>The contest process usually takes between 42 t...</td>\n",
       "      <td>https://github.com/code-423n4/docs/blob/main//...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>how does certification work?</td>\n",
       "      <td>Certification works through a process where an...</td>\n",
       "      <td>https://github.com/code-423n4/docs/blob/main//...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Can I use bots to analyze code?</td>\n",
       "      <td>Yes, you can use bots to analyze code. Code4re...</td>\n",
       "      <td>https://code4rena.com/how-it-works, https://co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>What is a lookout?</td>\n",
       "      <td>In the context of Code4rena, a lookout is a ro...</td>\n",
       "      <td>https://github.com/code-423n4/docs/blob/main//...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>what's a scout?</td>\n",
       "      <td>In the context of Code4rena, a Scout is a role...</td>\n",
       "      <td>https://github.com/code-423n4/docs/blob/main//...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Am I allowed to use AI in an audit?</td>\n",
       "      <td>Yes, you are allowed to use AI in an audit. Ho...</td>\n",
       "      <td>https://github.com/code-423n4/docs/blob/main//...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Can I change my Code4rena username?</td>\n",
       "      <td>No, you cannot change your Code4rena username....</td>\n",
       "      <td>https://code4rena.com/register</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>How do I book a solo audit?</td>\n",
       "      <td>To book a solo audit, a project team member sh...</td>\n",
       "      <td>https://github.com/code-423n4/docs/blob/main//...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Do I need to be certified to participate in an...</td>\n",
       "      <td>Yes, you need to be a certified contributor to...</td>\n",
       "      <td>https://github.com/code-423n4/docs/blob/main//...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>How do bot races work?</td>\n",
       "      <td>Bot races work in two stages. In the first sta...</td>\n",
       "      <td>https://code4rena.com/how-it-works, https://co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Can I change my Code4rena profile name?</td>\n",
       "      <td>The documents do not provide information on wh...</td>\n",
       "      <td>https://code4rena.com/register, https://github...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>What are scout awards?</td>\n",
       "      <td>Scout awards are part of the incentive model u...</td>\n",
       "      <td>https://github.com/code-423n4/docs/blob/main//...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>What are analysis reports?</td>\n",
       "      <td>Analysis reports are written submissions that ...</td>\n",
       "      <td>https://github.com/code-423n4/docs/blob/main//...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>what is an analysis finding?</td>\n",
       "      <td>An analysis finding is a written submission th...</td>\n",
       "      <td>https://github.com/code-423n4/docs/blob/main//...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>My name wasn't in the award announcements. Whe...</td>\n",
       "      <td>You can confirm that Code4rena has received yo...</td>\n",
       "      <td>https://github.com/code-423n4/docs/blob/main//...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>How long does the certification process take?</td>\n",
       "      <td>Once you submit the certified contributor appl...</td>\n",
       "      <td>https://github.com/code-423n4/docs/blob/main//...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>How can I access findings.csv?</td>\n",
       "      <td>To access findings.csv, you need to sign into ...</td>\n",
       "      <td>https://github.com/code-423n4/docs/blob/main//...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Can I use chatgpt?</td>\n",
       "      <td>The use of ChatGPT or similar automated tools ...</td>\n",
       "      <td>https://github.com/code-423n4/docs/blob/main//...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             question  \\\n",
       "0                 Hi, how can I get backstage access?   \n",
       "1   how long does it take until findings are relea...   \n",
       "2                     When can I talk about findings?   \n",
       "3                  How do I change my wallet address?   \n",
       "4                                    What are scouts?   \n",
       "5     How long does the contest process usually take?   \n",
       "6                        how does certification work?   \n",
       "7                     Can I use bots to analyze code?   \n",
       "8                                  What is a lookout?   \n",
       "9                                     what's a scout?   \n",
       "10                Am I allowed to use AI in an audit?   \n",
       "11                Can I change my Code4rena username?   \n",
       "12                        How do I book a solo audit?   \n",
       "13  Do I need to be certified to participate in an...   \n",
       "14                             How do bot races work?   \n",
       "15            Can I change my Code4rena profile name?   \n",
       "16                             What are scout awards?   \n",
       "17                         What are analysis reports?   \n",
       "18                       what is an analysis finding?   \n",
       "19  My name wasn't in the award announcements. Whe...   \n",
       "20      How long does the certification process take?   \n",
       "21                     How can I access findings.csv?   \n",
       "22                                 Can I use chatgpt?   \n",
       "\n",
       "                                          Bot answers  \\\n",
       "0   To get backstage access, you need to meet the ...   \n",
       "1   The findings are released between 42 to 60 day...   \n",
       "2   You can talk about findings after they are mad...   \n",
       "3   You can change your wallet address by logging ...   \n",
       "4   Scouts in the context of Code4rena focus on sc...   \n",
       "5   The contest process usually takes between 42 t...   \n",
       "6   Certification works through a process where an...   \n",
       "7   Yes, you can use bots to analyze code. Code4re...   \n",
       "8   In the context of Code4rena, a lookout is a ro...   \n",
       "9   In the context of Code4rena, a Scout is a role...   \n",
       "10  Yes, you are allowed to use AI in an audit. Ho...   \n",
       "11  No, you cannot change your Code4rena username....   \n",
       "12  To book a solo audit, a project team member sh...   \n",
       "13  Yes, you need to be a certified contributor to...   \n",
       "14  Bot races work in two stages. In the first sta...   \n",
       "15  The documents do not provide information on wh...   \n",
       "16  Scout awards are part of the incentive model u...   \n",
       "17  Analysis reports are written submissions that ...   \n",
       "18  An analysis finding is a written submission th...   \n",
       "19  You can confirm that Code4rena has received yo...   \n",
       "20  Once you submit the certified contributor appl...   \n",
       "21  To access findings.csv, you need to sign into ...   \n",
       "22  The use of ChatGPT or similar automated tools ...   \n",
       "\n",
       "                                              Sources  \n",
       "0   https://github.com/code-423n4/docs/blob/main//...  \n",
       "1   https://github.com/code-423n4/docs/blob/main//...  \n",
       "2   https://github.com/code-423n4/docs/blob/main//...  \n",
       "3   https://github.com/code-423n4/docs/blob/main//...  \n",
       "4   https://code4rena.com/how-it-works, https://gi...  \n",
       "5   https://github.com/code-423n4/docs/blob/main//...  \n",
       "6   https://github.com/code-423n4/docs/blob/main//...  \n",
       "7   https://code4rena.com/how-it-works, https://co...  \n",
       "8   https://github.com/code-423n4/docs/blob/main//...  \n",
       "9   https://github.com/code-423n4/docs/blob/main//...  \n",
       "10  https://github.com/code-423n4/docs/blob/main//...  \n",
       "11                     https://code4rena.com/register  \n",
       "12  https://github.com/code-423n4/docs/blob/main//...  \n",
       "13  https://github.com/code-423n4/docs/blob/main//...  \n",
       "14  https://code4rena.com/how-it-works, https://co...  \n",
       "15  https://code4rena.com/register, https://github...  \n",
       "16  https://github.com/code-423n4/docs/blob/main//...  \n",
       "17  https://github.com/code-423n4/docs/blob/main//...  \n",
       "18  https://github.com/code-423n4/docs/blob/main//...  \n",
       "19  https://github.com/code-423n4/docs/blob/main//...  \n",
       "20  https://github.com/code-423n4/docs/blob/main//...  \n",
       "21  https://github.com/code-423n4/docs/blob/main//...  \n",
       "22  https://github.com/code-423n4/docs/blob/main//...  "
      ]
     },
     "execution_count": 577,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "    \"question\": [q for q in eval_set],\n",
    "    \"Bot answers\": [r['answer'] for r in eval_results],\n",
    "    \"Sources\": [ \", \".join(r['source_urls']) for r in eval_results],\n",
    "})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(\"./outputs/eval_results.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Question"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "ORIGINAL: My wallet was hacked. What do I do?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Answer"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "If your wallet was hacked, follow these steps:\n",
       "\n",
       "1. If you are not logged in and you haven't set up your password yet, click \"Log in\" from the connect dropdown and then click \"forgot password\" to get a password reset link.\n",
       "2. Log in with your username and password.\n",
       "3. Update your payment addresses from the account page.\n",
       "4. Submit a help request through the Help Desk while logged in so that the hacked wallet can be removed from your account.\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Sources"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://github.com/code-423n4/docs/blob/main//roles/wardens/warden-auth.md\n"
     ]
    }
   ],
   "source": [
    "ask(\"My wallet was hacked. What do I do?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "c4-chatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
